{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.loss_function import SaliencyLoss\n",
    "from utils.data_process import MyDataset\n",
    "\n",
    "flag = 1 # 0 for TranSalNet_Dense, 1 for TranSalNet_Res\n",
    "\n",
    "if flag:\n",
    "    from TranSalNet_Res import TranSalNet\n",
    "else:\n",
    "    from TranSalNet_Dense import TranSalNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑↑↑ Set flag=1 to load TranSalNet_Dense,set flag=0 to load TranSalNet_Res."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = pd.read_csv(r'datasets/train_ids.csv')\n",
    "val_ids = pd.read_csv(r'datasets/val_ids.csv')\n",
    "print(train_ids.iloc[1])\n",
    "print(val_ids.iloc[1])\n",
    "\n",
    "dataset_sizes = {'train':len(train_ids),'val':len(val_ids)}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑↑↑Load image id from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_set = MyDataset(ids=train_ids,\n",
    "                           stimuli_dir=r'datasets\\train\\train_stimuli/',\n",
    "                           saliency_dir=r'datasets\\train\\train_saliency/',\n",
    "                           fixation_dir=r'datasets\\train\\train_fixation/',\n",
    "                           transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                            ]))\n",
    "\n",
    "val_set = MyDataset(ids=val_ids,\n",
    "                        stimuli_dir=r'datasets\\val\\val_stimuli/',\n",
    "                        saliency_dir = r'datasets\\val\\val_saliency/',\n",
    "                         fixation_dir=r'datasets\\val\\val_fixation/',\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                            ]))\n",
    "\n",
    "\n",
    "\n",
    "dataloaders = {'train':DataLoader(train_set, batch_size=batch_size,shuffle=True, num_workers=4)\n",
    "               ,'val':DataLoader(val_set, batch_size=batch_size,shuffle=False, num_workers=4)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑↑↑Set batch_size and Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TranSalNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-5)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "loss_fn = SaliencyLoss()\n",
    "\n",
    "'''Training'''\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "num_epochs =30\n",
    "best_loss = 100\n",
    "for k,v in model.named_parameters():\n",
    "    print('{}: {}'.format(k, v.requires_grad))\n",
    "\n",
    "                 \n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        \n",
    "        # Iterate over data.\n",
    "        for i_batch, sample_batched in tqdm(enumerate(dataloaders[phase])):\n",
    "            stimuli, smap, fmap = sample_batched['image'], sample_batched['saliency'], sample_batched['fixation']\n",
    "            stimuli, smap, fmap = stimuli.type(torch.cuda.FloatTensor), smap.type(torch.cuda.FloatTensor), fmap.type(torch.cuda.FloatTensor)\n",
    "            stimuli, smap, fmap = stimuli.to(device), smap.to(device), fmap.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(stimuli)\n",
    "                \n",
    "\n",
    "\n",
    "                loss = -2*loss_fn(outputs,smap,loss_type='cc')\\\n",
    "                        -1*loss_fn(outputs,smap,loss_type='sim')+\\\n",
    "                        10*loss_fn(outputs,smap,loss_type='kldiv')-1*loss_fn(outputs,fmap,loss_type='nss')\n",
    "\n",
    "\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * stimuli.size(0)\n",
    "\n",
    "\n",
    "\n",
    "        if phase == 'train':\n",
    "            scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        \n",
    "            \n",
    "        print('{} Loss: {:.4f}'.format(\n",
    "            phase, epoch_loss))\n",
    "        \n",
    "        \n",
    "        if phase == 'val' and epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            counter = 0\n",
    "        elif phase == 'val' and epoch_loss >= best_loss:\n",
    "            counter += 1\n",
    "            if counter ==5:\n",
    "                print('early stop!')\n",
    "                break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "    print()\n",
    "\n",
    "\n",
    "print('Best val loss: {:4f}'.format(best_loss))\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = r'mymodel.pth'\n",
    "torch.save(model.state_dict(),savepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
